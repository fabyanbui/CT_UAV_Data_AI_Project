{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4297e2",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce1336",
   "metadata": {},
   "source": [
    "## True Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5e3773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Giai đoạn đào tạo cơ sở ---\n",
      "Epoch 1, Loss: 1.9536\n",
      "Epoch 2, Loss: 1.6171\n",
      "Epoch 3, Loss: 1.1455\n",
      "Epoch 4, Loss: 0.7560\n",
      "Epoch 5, Loss: 0.1160\n",
      "\n",
      "--- Giai đoạn tinh chỉnh (Few-shot) ---\n",
      "Epoch 1, Loss: 5.0564\n",
      "Epoch 2, Loss: 4.1135\n",
      "Epoch 3, Loss: 3.0515\n",
      "Epoch 4, Loss: 2.3637\n",
      "Epoch 5, Loss: 2.0044\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageFilter\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Giả lập kiến trúc mô hình\n",
    "# Sử dụng S^2A-Net làm nền tảng (như trong bài báo)\n",
    "# Do không có mã nguồn S^2A-Net, chúng ta sẽ mô phỏng nó\n",
    "class S2ANet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(S2ANet, self).__init__()\n",
    "        # Backbone: Giả lập ResNet\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # FPN (Feature Pyramid Network)\n",
    "        self.fpn = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Feature Alignment Module (FAM)\n",
    "        self.fam = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Định nghĩa các đầu ra cho phân loại và hồi quy\n",
    "        self.cls_head = nn.Linear(128, num_classes) # Classification head\n",
    "        self.reg_head = nn.Linear(128, 5) # Regression head (x, y, w, h, angle)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        fpn_features = self.fpn(features)\n",
    "        aligned_features = self.fam(fpn_features)\n",
    "        # Giả sử pooling để lấy một vector đặc trưng duy nhất\n",
    "        pooled_features = torch.mean(aligned_features, dim=[2, 3])\n",
    "        \n",
    "        cls_output = self.cls_head(pooled_features)\n",
    "        reg_output = self.reg_head(pooled_features)\n",
    "        \n",
    "        return cls_output, reg_output, pooled_features\n",
    "\n",
    "# Module Học Tương Phản Đáng Nhớ (Memorable Contrastive Learning - MCL)\n",
    "class MCL(nn.Module):\n",
    "    def __init__(self, feature_dim=128, memory_bank_size=4096, momentum=0.999):\n",
    "        super(MCL, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.memory_bank_size = memory_bank_size\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        # Hàng đợi (queue) để lưu trữ các đặc trưng và nhãn\n",
    "        self.memory_bank = deque(maxlen=self.memory_bank_size)\n",
    "        \n",
    "        # Projection Encoder: 2 lớp conv với 1 lớp ReLU\n",
    "        self.projection_encoder = nn.Sequential(\n",
    "            nn.Conv2d(feature_dim, feature_dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(feature_dim, feature_dim, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, proposals_features, proposal_labels, proposal_ious):\n",
    "        # Lấy các đặc trưng có IoU > ngưỡng (ví dụ 0.5)\n",
    "        # Điều này giúp loại bỏ các proposals không tốt\n",
    "        relevant_indices = (proposal_ious > 0.5)\n",
    "        if not torch.any(relevant_indices):\n",
    "            return torch.tensor(0.0) # Không có proposal phù hợp để tính loss\n",
    "        \n",
    "        relevant_features = proposals_features[relevant_indices]\n",
    "        relevant_labels = proposal_labels[relevant_indices]\n",
    "        \n",
    "        # Ánh xạ các đặc trưng vào không gian nhúng\n",
    "        embeddings = self.projection_encoder(relevant_features.unsqueeze(-1).unsqueeze(-1))\n",
    "        embeddings = embeddings.squeeze()\n",
    "        \n",
    "        # Chuẩn hóa các vector đặc trưng\n",
    "        embeddings = nn.functional.normalize(embeddings, dim=1)\n",
    "        \n",
    "        # Cập nhật ngân hàng bộ nhớ\n",
    "        for embed, label in zip(embeddings, relevant_labels):\n",
    "            self.memory_bank.append({'embedding': embed.detach(), 'label': label.item()})\n",
    "            \n",
    "        # Tính toán MCL loss\n",
    "        if len(self.memory_bank) < 2:\n",
    "            return torch.tensor(0.0)\n",
    "            \n",
    "        loss = 0.0\n",
    "        for i in range(len(embeddings)):\n",
    "            current_embed = embeddings[i]\n",
    "            current_label = relevant_labels[i].item()\n",
    "            \n",
    "            # Tính in-batch loss\n",
    "            for j in range(len(embeddings)):\n",
    "                if i != j:\n",
    "                    if relevant_labels[j].item() == current_label:\n",
    "                        loss += -torch.log(torch.exp(torch.dot(current_embed, embeddings[j])))\n",
    "                    else:\n",
    "                        loss += -torch.log(torch.exp(-torch.dot(current_embed, embeddings[j])))\n",
    "            \n",
    "            # Tính cross-batch loss (sử dụng memory bank)\n",
    "            for mem_entry in self.memory_bank:\n",
    "                mem_embed = mem_entry['embedding']\n",
    "                mem_label = mem_entry['label']\n",
    "                if mem_label == current_label:\n",
    "                    loss += -torch.log(torch.exp(torch.dot(current_embed, mem_embed)))\n",
    "                else:\n",
    "                    loss += -torch.log(torch.exp(-torch.dot(current_embed, mem_embed)))\n",
    "        \n",
    "        return loss / (len(embeddings) * (len(embeddings) + len(self.memory_bank) -1))\n",
    "\n",
    "\n",
    "# Kỹ thuật Shot Masking\n",
    "def apply_shot_masking(image, objects_to_keep, all_objects):\n",
    "    masked_image = image.copy()\n",
    "    for obj in all_objects:\n",
    "        if obj not in objects_to_keep:\n",
    "            # Giả lập làm mờ Gaussian cho các đối tượng không được chọn\n",
    "            x, y, w, h, angle = obj['bbox']\n",
    "            # Chuyển đổi OBB thành một vùng để làm mờ\n",
    "            box = (int(x - w/2), int(y - h/2), int(x + w/2), int(y + h/2)) # <-- Sửa lỗi ở đây\n",
    "            region = masked_image.crop(box)\n",
    "            region = region.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            masked_image.paste(region, box)\n",
    "    return masked_image\n",
    "\n",
    "# Giả lập quá trình đào tạo\n",
    "def train_model():\n",
    "    # Khởi tạo mô hình và các module\n",
    "    model = S2ANet(num_classes=5)\n",
    "    mcl_module = MCL()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Giả lập dữ liệu đào tạo (hình ảnh và nhãn)\n",
    "    base_data = [{'image': Image.new('RGB', (256, 256)), 'labels': [0, 1]}, {'image': Image.new('RGB', (256, 256)), 'labels': [0, 1]}]\n",
    "    novel_data = [{'image': Image.new('RGB', (256, 256)), 'labels': [2, 3]}, {'image': Image.new('RGB', (256, 256)), 'labels': [4]}]\n",
    "    \n",
    "    # Giai đoạn đào tạo cơ sở\n",
    "    print(\"--- Giai đoạn đào tạo cơ sở ---\")\n",
    "    for epoch in range(5):\n",
    "        for data in base_data:\n",
    "            img = T.ToTensor()(data['image']).unsqueeze(0)\n",
    "            cls_output, reg_output, _ = model(img)\n",
    "            # Giả lập tính toán loss\n",
    "            cls_loss = nn.CrossEntropyLoss()(cls_output, torch.tensor([data['labels'][0]]))\n",
    "            reg_loss = nn.MSELoss()(reg_output, torch.rand(1, 5))\n",
    "            total_loss = cls_loss + reg_loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss.item():.4f}\")\n",
    "        \n",
    "    # Giai đoạn tinh chỉnh với dữ liệu few-shot\n",
    "    print(\"\\n--- Giai đoạn tinh chỉnh (Few-shot) ---\")\n",
    "    # Đóng băng backbone\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    for epoch in range(5):\n",
    "        for data in novel_data:\n",
    "            # Áp dụng Shot Masking (giả lập)\n",
    "            # Giả định chỉ chọn một số đối tượng để training\n",
    "            selected_objects = [{'bbox': (100, 100, 50, 80, 45)}]\n",
    "            all_objects = [{'bbox': (100, 100, 50, 80, 45)}, {'bbox': (150, 150, 30, 60, 0)}]\n",
    "            masked_img = apply_shot_masking(data['image'], selected_objects, all_objects)\n",
    "            img = T.ToTensor()(masked_img).unsqueeze(0)\n",
    "            \n",
    "            cls_output, reg_output, features = model(img)\n",
    "            \n",
    "            # Tính các loss\n",
    "            cls_loss = nn.CrossEntropyLoss()(cls_output, torch.tensor([data['labels'][0]]))\n",
    "            reg_loss = nn.MSELoss()(reg_output, torch.rand(1, 5))\n",
    "            \n",
    "            # Tính MCL loss (giả lập proposals)\n",
    "            proposals = torch.rand(10, 128) # Giả lập 10 proposals\n",
    "            ious = torch.rand(10)\n",
    "            labels = torch.randint(0, 5, (10,))\n",
    "            mcl_loss = mcl_module(proposals, labels, ious)\n",
    "            \n",
    "            # Tổng loss\n",
    "            total_loss = cls_loss + reg_loss + 0.1 * mcl_loss # 0.1 là hyperparameter lambda\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss.item():.4f}\")\n",
    "    \n",
    "# Chạy demo\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542f9f4",
   "metadata": {},
   "source": [
    "## True Code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2c89e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Memorable Contrastive Learning logic...\n",
      "--- Kết quả mô hình khái niệm ---\n",
      "Dự đoán hộp giới hạn: torch.Size([1, 5, 16, 16])\n",
      "Giá trị Contrastive Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Giả định các module phức tạp đã được định nghĩa\n",
    "# Thay thế cho việc triển khai thực tế của các thành phần trong bài báo\n",
    "\n",
    "class OrientedDetectorHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Module đầu (head) cho phát hiện đối tượng định hướng.\n",
    "    Thành phần này dự đoán các hộp giới hạn xoay (góc, chiều dài, chiều rộng, tâm).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        # Triển khai các lớp tích chập và lớp kết nối đầy đủ để dự đoán\n",
    "        # 5 giá trị cho mỗi hộp: (x, y, w, h, theta)\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=3, padding=1)\n",
    "        self.output = nn.Conv2d(256, 5, kernel_size=1) # Ví dụ, 5 giá trị cho hộp xoay\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.output(self.conv1(features))\n",
    "\n",
    "class MemorableContrastiveLearning(nn.Module):\n",
    "    \"\"\"\n",
    "    Module học tương phản đáng nhớ (MCL).\n",
    "    Sử dụng các prototype được lưu trữ để so sánh và học.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_base_classes, feature_dim):\n",
    "        super().__init__()\n",
    "        # Bộ nhớ để lưu trữ các prototype của các lớp cơ sở\n",
    "        # Trong thực tế, đây là một bộ nhớ động được cập nhật trong quá trình huấn luyện\n",
    "        self.register_buffer(\"prototypes\", torch.zeros(num_base_classes, feature_dim))\n",
    "\n",
    "    def forward(self, support_features, support_labels, query_features):\n",
    "        # Đây là nơi logic phức tạp của MCL diễn ra.\n",
    "        # 1. Trích xuất prototype từ các mẫu hỗ trợ (support samples).\n",
    "        # 2. So sánh đặc trưng của các mẫu truy vấn (query samples)\n",
    "        #    với các prototype trong bộ nhớ.\n",
    "        # 3. Tính toán loss tương phản (contrastive loss)\n",
    "        #    để kéo các đặc trưng của cùng một lớp lại gần nhau.\n",
    "        print(\"Executing Memorable Contrastive Learning logic...\")\n",
    "        # Mã thực tế ở đây sẽ rất phức tạp và cần dữ liệu support/query.\n",
    "        # Vì đây là demo khái niệm, ta chỉ in ra thông báo.\n",
    "        return torch.tensor(0.0) # Trả về một giá trị loss giả định\n",
    "\n",
    "class FOMC_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Mô hình phát hiện đối tượng FOMC hoàn chỉnh\n",
    "    \"\"\"\n",
    "    def __init__(self, num_base_classes=10, feature_dim=512):\n",
    "        super().__init__()\n",
    "        # Backbone: Để trích xuất đặc trưng từ hình ảnh\n",
    "        # Bài báo có thể sử dụng các mạng mạnh hơn như ResNet-50 hoặc ResNet-101\n",
    "        self.backbone = resnet18(weights=None)\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "\n",
    "        # Head để phát hiện đối tượng\n",
    "        self.oriented_head = OrientedDetectorHead(in_channels=feature_dim)\n",
    "\n",
    "        # Module học tương phản\n",
    "        self.mcl_module = MemorableContrastiveLearning(num_base_classes, feature_dim)\n",
    "        \n",
    "    def forward(self, images, support_data=None, query_data=None):\n",
    "        # Trích xuất đặc trưng từ hình ảnh\n",
    "        features = self.backbone(images)\n",
    "\n",
    "        # Dự đoán các hộp giới hạn định hướng\n",
    "        detections = self.oriented_head(features)\n",
    "        \n",
    "        # Tính toán loss tương phản nếu dữ liệu hỗ trợ được cung cấp\n",
    "        contrastive_loss = torch.tensor(0.0)\n",
    "        if support_data and query_data:\n",
    "            support_features = self.backbone(support_data[\"images\"])\n",
    "            query_features = self.backbone(query_data[\"images\"])\n",
    "            contrastive_loss = self.mcl_module(\n",
    "                support_features, support_data[\"labels\"], query_features\n",
    "            )\n",
    "\n",
    "        return detections, contrastive_loss\n",
    "\n",
    "\n",
    "# --- Cách sử dụng (khái niệm) ---\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = FOMC_Model()\n",
    "\n",
    "# Giả định dữ liệu đầu vào\n",
    "# Một batch hình ảnh có kích thước (batch_size, channels, height, width)\n",
    "dummy_image = torch.randn(1, 3, 512, 512)\n",
    "\n",
    "# Giả định dữ liệu ít mẫu (few-shot)\n",
    "# Trong quá trình huấn luyện thực tế, các tập này được tạo động\n",
    "# từ dataset cơ sở.\n",
    "dummy_support_data = {\n",
    "    \"images\": torch.randn(5, 3, 512, 512),\n",
    "    \"labels\": torch.tensor([1, 2, 3, 4, 5])\n",
    "}\n",
    "dummy_query_data = {\n",
    "    \"images\": torch.randn(10, 3, 512, 512)\n",
    "}\n",
    "\n",
    "# Chạy forward pass\n",
    "detections, contrastive_loss = model(\n",
    "    images=dummy_image,\n",
    "    support_data=dummy_support_data,\n",
    "    query_data=dummy_query_data\n",
    ")\n",
    "\n",
    "print(\"--- Kết quả mô hình khái niệm ---\")\n",
    "print(\"Dự đoán hộp giới hạn:\", detections.shape)\n",
    "print(\"Giá trị Contrastive Loss:\", contrastive_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b506cde",
   "metadata": {},
   "source": [
    "## True Code 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438a2209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch 0, Loss 2.9247\n",
      "Epoch 1, Loss 2.3868\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchgeo.datasets import VHR10\n",
    "import random\n",
    "\n",
    "# ----- Step 1: Load dataset -----\n",
    "def preprocess(sample):\n",
    "    sample[\"image\"] = sample[\"image\"].float() / 255.0\n",
    "    return sample\n",
    "\n",
    "ds = VHR10(\n",
    "    root=\"data/VHR10/\",\n",
    "    split=\"positive\",\n",
    "    transforms=preprocess,\n",
    "    download=True,\n",
    "    checksum=True,\n",
    ")\n",
    "\n",
    "# ----- Step 2: Split base vs novel classes -----\n",
    "# NWPU VHR-10: 10 classes (1–10). Giả sử chọn 3 novel classes: airplane=1, baseball diamond=4, tennis court=5\n",
    "novel_classes = [1, 4, 5]\n",
    "base_classes = [c for c in range(1, 11) if c not in novel_classes]\n",
    "\n",
    "base_indices, novel_indices = [], []\n",
    "for i in range(len(ds)):\n",
    "    labels = ds[i][\"label\"]\n",
    "    if any(l in novel_classes for l in labels):\n",
    "        novel_indices.append(i)\n",
    "    else:\n",
    "        base_indices.append(i)\n",
    "\n",
    "base_ds = Subset(ds, base_indices)\n",
    "novel_ds = Subset(ds, novel_indices)\n",
    "\n",
    "# Few-shot: chọn K=5 ảnh cho mỗi novel class\n",
    "K = 5\n",
    "fewshot_indices = []\n",
    "for cls in novel_classes:\n",
    "    cls_idxs = [i for i in novel_indices if cls in ds[i][\"label\"]]\n",
    "    fewshot_indices.extend(random.sample(cls_idxs, min(K, len(cls_idxs))))\n",
    "fewshot_ds = Subset(ds, fewshot_indices)\n",
    "\n",
    "# ----- Step 3: Model (toy Faster R-CNN) -----\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=\"DEFAULT\"\n",
    ")\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "    in_features, 11  # 10 classes + background\n",
    ")\n",
    "\n",
    "# ----- Step 4: Memory Bank for MCL -----\n",
    "class MemoryBank:\n",
    "    def __init__(self, size=8192, feat_dim=256, device=\"cpu\"):\n",
    "        self.size = size\n",
    "        self.ptr = 0\n",
    "        self.feats = torch.zeros(size, feat_dim, device=device)\n",
    "        self.labels = torch.zeros(size, dtype=torch.long, device=device)\n",
    "\n",
    "    def update(self, feats, labels):\n",
    "        bsz = labels.shape[0]   # <-- luôn sync với labels\n",
    "        if bsz > self.size:\n",
    "            feats, labels = feats[:self.size], labels[:self.size]\n",
    "            bsz = self.size\n",
    "\n",
    "        idxs = (self.ptr + torch.arange(bsz)) % self.size\n",
    "        idxs = idxs.long().to(self.feats.device)\n",
    "\n",
    "        # Debug\n",
    "        # print(\"update:\", bsz, feats.shape, labels.shape, idxs.shape)\n",
    "\n",
    "        self.feats[idxs] = feats.detach()\n",
    "        # self.labels[idxs] = labels.detach()\n",
    "        self.labels[idxs] = labels.detach().view(-1)[:len(idxs)]\n",
    "\n",
    "        self.ptr = (self.ptr + bsz) % self.size\n",
    "\n",
    "    def get(self):\n",
    "        return self.feats, self.labels\n",
    "\n",
    "def supervised_contrastive_loss(features, labels, memory_feats, memory_labels, temperature=0.1):\n",
    "    # Normalize\n",
    "    features = F.normalize(features, dim=1)\n",
    "    memory_feats = F.normalize(memory_feats, dim=1)\n",
    "\n",
    "    logits = torch.mm(features, memory_feats.t()) / temperature\n",
    "    labels = labels.view(-1, 1)\n",
    "    mask = (labels == memory_labels.view(1, -1)).float()\n",
    "\n",
    "    exp_logits = torch.exp(logits)\n",
    "    log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "    loss = -(mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "    return loss.mean()\n",
    "\n",
    "# ----- Step 5: Training Loop (pseudo) -----\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "memory = MemoryBank(size=1024, feat_dim=in_features)\n",
    "\n",
    "# def extract_roi_features(model, images, targets):\n",
    "#     # Toy: use box_head from FasterRCNN to get features\n",
    "#     features = model.backbone(images.tensors)\n",
    "#     return features  # placeholder (need integration with roi_heads)\n",
    "\n",
    "def extract_gt_features(model, images, targets):\n",
    "    # Transform\n",
    "    transformed = model.transform(images, targets)\n",
    "    images_t, targets_t = transformed\n",
    "\n",
    "    # Backbone\n",
    "    features = model.backbone(images_t.tensors)\n",
    "    if isinstance(features, torch.Tensor):\n",
    "        features = {\"0\": features}\n",
    "\n",
    "    # Lấy gt boxes làm proposal\n",
    "    proposals = [t[\"boxes\"] for t in targets_t]\n",
    "\n",
    "    # ROI Pooling trên GT boxes\n",
    "    box_features = model.roi_heads.box_roi_pool(\n",
    "        features, proposals, images_t.image_sizes\n",
    "    )\n",
    "    # Head\n",
    "    box_features = model.roi_heads.box_head(box_features)\n",
    "\n",
    "    labels = torch.cat([t[\"labels\"] for t in targets_t])\n",
    "    return box_features, labels\n",
    "\n",
    "for epoch in range(2):  # demo only\n",
    "    for batch in DataLoader(fewshot_ds, batch_size=2, shuffle=True, collate_fn=lambda x: x):\n",
    "        images = [s[\"image\"] for s in batch]\n",
    "        targets = []\n",
    "        for s in batch:\n",
    "            boxes = s[\"bbox_xyxy\"]\n",
    "            labels = s[\"label\"]\n",
    "            targets.append({\"boxes\": boxes, \"labels\": labels})\n",
    "\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        detection_loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # MCL: giả sử có roi_feats (cần implement thêm)\n",
    "        # roi_feats = torch.randn(len(targets), in_features, device=device)  # placeholder\n",
    "        # roi_labels = torch.cat([t[\"labels\"] for t in targets])\n",
    "\n",
    "        roi_feats, roi_labels = extract_gt_features(model, images, targets)\n",
    "\n",
    "        memory_feats, memory_labels = memory.get()\n",
    "        memory_feats, memory_labels = memory_feats.to(device), memory_labels.to(device)\n",
    "\n",
    "        if memory_labels.sum() > 0:\n",
    "            mcl_loss = supervised_contrastive_loss(roi_feats, roi_labels, memory_feats, memory_labels)\n",
    "        else:\n",
    "            mcl_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        loss = detection_loss + 0.3 * mcl_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        memory.update(roi_feats.cpu(), roi_labels.cpu())\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
